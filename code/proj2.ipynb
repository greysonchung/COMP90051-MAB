{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Project 2\n",
    "\n",
    "**Copyright statement:** This notebook is copyright University of Melbourne. \n",
    "It is licensed for the sole purpose of your assessment in COMP90051. \n",
    "You are not permitted to share or publish derived versions of this notebook, other than with COMP90051 staff for assessment.\n",
    "\n",
    "***\n",
    "\n",
    "The code block below imports the namespaces/functions/classes you may use in the project. \n",
    "Additional imports are not permitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit. These are the only imports permitted.\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Type annotations\n",
    "from numpy import ndarray\n",
    "from numpy.random import Generator\n",
    "from typing import List, Optional, Tuple, Callable\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  # for Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base `MAB` class below defines a common interface for a contextual multi-armed bandit. \n",
    "Your bandit implementations in Parts 1-4 should inherit from this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAB(ABC):\n",
    "    \"\"\"Base class for a contextual multi-armed bandit (MAB)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_arms : int\n",
    "        Number of arms.\n",
    "        \n",
    "    rng : Generator, optional\n",
    "        A `Generator` used as an internal source of randomness. If None, a \n",
    "        default `Generator` will be constructed using `np.random.default_rng`.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_arms: int, rng: Optional[Generator] = None) -> None:\n",
    "        if not n_arms >= 0:\n",
    "            raise ValueError(\"`n_arms` must be non-negative\")\n",
    "        self.n_arms = n_arms\n",
    "        self.rng = np.random.default_rng(rng)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def play(self, context: Optional[ndarray] = None) -> int:\n",
    "        \"\"\"Play a round\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        context : float numpy.ndarray, shape (n_arms, n_dims), optional\n",
    "            An array of context vectors presented to the MAB. The 0-th \n",
    "            axis indexes the arms, and the 1-st axis indexes the features.\n",
    "            Non-contextual bandits accept a context of None.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        arm : int\n",
    "            Integer index of the arm played this round. Should be in the set \n",
    "            {0, ..., n_arms - 1}.\n",
    "        \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update(self, arm: int, reward: float, context: Optional[ndarray] = None) -> None:\n",
    "        \"\"\"Update the internal state of the MAB after a play\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        arm : int\n",
    "            Integer index of the played arm in the set {0, ..., n_arms - 1}.\n",
    "            \n",
    "        reward : float\n",
    "            Reward received from the arm.\n",
    "        \n",
    "        context : float numpy.ndarray, shape (n_arms, n_dims), optional\n",
    "            An array of context vectors that was presented to the MAB. The \n",
    "            0-th axis indexes the arms, and the 1-st axis indexes the \n",
    "            features. Non-contextual bandits accept a context of None.\n",
    "        \"\"\"\n",
    "        if arm >= self.n_arms or arm < 0:\n",
    "            raise ValueError(\"`arm` must be in the range \"\n",
    "                             \"[0, {}]\".format(self.n_arms - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below implements off-policy evaluation as described in Appendix A of the project spec. \n",
    "You should use it—along with the provided dataset—to evaluate the bandits in Parts 1-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_eval(mab: MAB, arms: ndarray, rewards: ndarray, contexts: ndarray, \n",
    "                 n_rounds: Optional[int] = None) -> ndarray:\n",
    "    \"\"\"Offline evaluation of a multi-armed bandit\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mab : instance of MAB\n",
    "        MAB to evaluate.\n",
    "    \n",
    "    arms : int ndarray, shape (n_events,) \n",
    "        Array containing the history of pulled arms, represented as integer \n",
    "        indices in the set {0, ..., mab.n_arms}\n",
    "    \n",
    "    rewards : float ndarray, shape (n_events,)\n",
    "        Array containing the history of rewards. If a reward is missing, it \n",
    "        should be represented by `np.nan`.\n",
    "    \n",
    "    contexts : float ndarray, shape (n_events, n_arms, n_dims)\n",
    "        Array containing the history of contexts presented to the arms. \n",
    "        The 0-th axis indexes the events in the history, the 1-st axis \n",
    "        indexes the arms and the 2-nd axis indexed the features.\n",
    "        \n",
    "    n_rounds : int, optional\n",
    "        Number of matching events to evaluate the MAB on. If None, \n",
    "        continue evaluating until the historical events are exhausted.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matching_rewards : ndarray\n",
    "        Rewards of matched events.\n",
    "    \"\"\"\n",
    "    # Check types\n",
    "    if not isinstance(mab, MAB):\n",
    "        raise TypeError(\"`mab` must be an instance of MAB\")\n",
    "    arms = np.asarray(arms)\n",
    "    rewards = np.asarray(rewards)\n",
    "    contexts = np.asarray(contexts)\n",
    "    if n_rounds is not None and n_rounds < 0:\n",
    "        raise ValueError(\"`n_rounds` must be non-negative\")\n",
    "    \n",
    "    # Check array dimensions\n",
    "    if arms.ndim != 1:\n",
    "        raise ValueError(\"`arms` must be a 1D array\")\n",
    "    if rewards.ndim != 1:\n",
    "        raise ValueError(\"`rewards` must be a 1D array\")\n",
    "    if contexts.ndim != 3:\n",
    "        raise ValueError(\"`contexts` must be a 3D array\")\n",
    "    if not (arms.shape[0] == rewards.shape[0] == contexts.shape[0]):\n",
    "        raise ValueError(\"first dimension of input arrays are inconsistent\")\n",
    "    if contexts.shape[1] != mab.n_arms:\n",
    "        raise ValueError(\"`contexts` has inconsistent second dimension\")\n",
    "    if arms.max() >= mab.n_arms or arms.min() < 0:\n",
    "        raise ValueError(\"`arms` contains ids that are out-of-range\")\n",
    "    \n",
    "    matched_ctr = 0\n",
    "    matched_ids = list()\n",
    "    for i in range(arms.size):\n",
    "        if n_rounds is not None and matched_ctr >= n_rounds: # Note: fixed\n",
    "            break\n",
    "        arm_id = mab.play(contexts[i])\n",
    "        if arm_id == arms[i]:\n",
    "            reward = None if np.isnan(rewards[i]) else rewards[i]\n",
    "            mab.update(arm_id, reward, contexts[i])\n",
    "            matched_ctr += 1\n",
    "            matched_ids.append(i)\n",
    "    \n",
    "    return rewards[matched_ids], matched_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please define any static functions/variables (used across multiple tasks) in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(90051)  # Random generator used throughout\n",
    "\n",
    "# Define additional static functions/variables here, if required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Thompson sampling MAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TS(...):\n",
    "    \"\"\"Thompson sampling MAB with a Beta-Bernoulli reward model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_arms : int\n",
    "        Number of arms.\n",
    "\n",
    "    alpha0: float, optional\n",
    "        positive real prior hyperparameter\n",
    "\n",
    "    beta0: float, optional\n",
    "        positive real prior hyperparameter\n",
    "    \n",
    "    rng : Generator, optional\n",
    "        A `Generator` used as an internal source of randomness. If None, a \n",
    "        default `Generator` will be constructed using `np.random.default_rng`.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_arms: int, alpha0: float = 1.0, beta0: float = 1.0, \n",
    "                 rng: Optional[Generator] = None) -> None:\n",
    "        ... # implement or remove this method\n",
    "        \n",
    "    def play(self, context: Optional[ndarray] = None) -> int:\n",
    "        ... # implement or remove this method\n",
    "        \n",
    "    def update(self, arm: int, reward: float, context: Optional[ndarray] = None) -> None:\n",
    "        ... # implement or remove this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset here\n",
    "arms = ...\n",
    "rewards = ...\n",
    "contexts = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab = TS(10, alpha0=1.0, beta0=1.0, rng=rng)\n",
    "TS_rewards, TS_ids = offline_eval(mab, arms, rewards, contexts, n_rounds=800)\n",
    "print('TS average reward', np.mean(TS_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use additional cells here for experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Thompson sampling contextual MAB with linear payoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinTS(...):\n",
    "    \"\"\"Thompson sampling contextual MAB with a ridge regression reward model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_arms : int\n",
    "        Number of arms.\n",
    "    \n",
    "    n_dims : int\n",
    "        Number of dimensions for each arm's context.\n",
    "        \n",
    "    v: float, optional\n",
    "        Positive real explore-exploit parameter\n",
    "    \n",
    "    rng : Generator, optional\n",
    "        A `Generator` used as an internal source of randomness. If None, a \n",
    "        default `Generator` will be constructed using `np.random.default_rng`.\n",
    "    \"\"\"    \n",
    "    def __init__(self, n_arms: int, n_dims: int, v: float = 1.0, \n",
    "                 rng: Optional[Generator] = None) -> None:\n",
    "        ... # implement or remove this method\n",
    "        \n",
    "    def play(self, context: Optional[ndarray] = None) -> int:\n",
    "        ... # implement or remove this method\n",
    "    \n",
    "    def update(self, arm: int, reward: float, context: Optional[ndarray] = None) -> None:\n",
    "        ... # implement or remove this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab = LinTS(10, 10, v=1.0, rng=rng)\n",
    "LinTS_rewards, LinTS_ids = offline_eval(mab, arms, rewards, contexts, n_rounds=800)\n",
    "print('LinTS average reward', np.mean(LinTS_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use additional cells here for experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Thompson sampling MABs with fair exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairXTS(...):\n",
    "    \"\"\"FairX Thompson sampling MAB with a Beta-Bernoulli reward model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_arms : int\n",
    "        Number of arms.\n",
    "\n",
    "    c : float, optional\n",
    "        Scaling factor for expected reward in exponential merit function\n",
    "    \n",
    "    alpha0: float, optional\n",
    "        Positive real prior hyperparameter.\n",
    "\n",
    "    beta0: float, optional\n",
    "        Positive real prior hyperparameter.\n",
    "    \n",
    "    rng : Generator, optional\n",
    "        A `Generator` used as an internal source of randomness. If None, a \n",
    "        default `Generator` will be constructed using `np.random.default_rng`.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_arms: int, c: float = 1.0, alpha0: float = 1.0, \n",
    "                 beta0: float = 1.0, rng: Optional[Generator] = None) -> None:\n",
    "        ... # implement or remove this method\n",
    "    \n",
    "    def play(self, context: Optional[ndarray] = None) -> int:\n",
    "        ... # implement or remove this method\n",
    "    \n",
    "    def update(self, arm: int, reward: float, context: Optional[ndarray] = None) -> None:\n",
    "        ... # implement or remove this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab = FairXTS(10, c=1.0, alpha0=1.0, beta0=1.0, rng=rng)\n",
    "FairXTS_rewards, FairXTS_ids = offline_eval(mab, arms, rewards, contexts, n_rounds=800)\n",
    "print('FairX-TS average reward', np.mean(FairXTS_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use additional cells here for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairXLinTS(...):\n",
    "    \"\"\"FairX Thompson sampling contextual MAB with a ridge regression reward model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_arms : int\n",
    "        Number of arms.\n",
    "    \n",
    "    n_dims : int\n",
    "        Number of dimensions for each arm's context.\n",
    "    \n",
    "    c : float, optional\n",
    "        Scaling factor for expected reward in exponential merit function\n",
    "    \n",
    "    v: float, optional\n",
    "        Positive real explore-exploit parameter\n",
    "    \n",
    "    rng : Generator, optional\n",
    "        A `Generator` used as an internal source of randomness. If None, a \n",
    "        default `Generator` will be constructed using `np.random.default_rng`.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_arms: int, n_dims: int, c: float = 1.0, \n",
    "                 v: float = 1.0, rng: Optional[Generator] = None) -> None:\n",
    "        ... # implement or remove this method\n",
    "    \n",
    "    def play(self, context: Optional[ndarray] = None) -> int:\n",
    "        ... # implement or remove this method\n",
    "    \n",
    "    def update(self, arm: int, reward: float, context: Optional[ndarray] = None) -> None:\n",
    "        ... # implement or remove this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab = FairXLinTS(10, 10, c=1.0, v=1.0, rng=rng)\n",
    "FairXLinTS_rewards, FairXLinTS_ids = offline_eval(mab, arms, rewards, contexts, n_rounds=800)\n",
    "print('FairX-LinTS average reward', np.mean(FairXLinTS_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use additional cells here for experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: SquareCB contextual MAB with a logistic regression oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareCB(...):\n",
    "    \"\"\"SquareCB contextual MAB with a logistic regression oracle\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_arms : int\n",
    "        Number of arms.\n",
    "\n",
    "    n_dims : int\n",
    "        Number of features for each arm's context.\n",
    "    \n",
    "    gamma : float, optional\n",
    "        Learning rate parameter.\n",
    "    \n",
    "    rng : Generator, optional\n",
    "        A `Generator` used as an internal source of randomness. If None, a \n",
    "        default `Generator` will be constructed using `np.random.default_rng`.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_arms: int, n_dims: int, gamma: float = 1.0, \n",
    "                 rng: Optional[Generator] = None) -> None:\n",
    "        ... # implement or remove this method\n",
    "    \n",
    "    def play(self, context: Optional[ndarray] = None) -> int:\n",
    "        ... # implement or remove this method\n",
    "    \n",
    "    def update(self, arm: int, reward: float, \n",
    "               context: Optional[ndarray] = None) -> None:\n",
    "        ... # implement or remove this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mab = SquareCB(10, 10, gamma=18.0, rng=rng)\n",
    "SquareCB_rewards, SquareCB_ids = offline_eval(mab, arms, rewards, contexts, n_rounds=800)\n",
    "print('SquareCB average reward', np.mean(SquareCB_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use additional cells here for experimentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
