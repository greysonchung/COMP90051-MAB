# COMP90051 Assignment 2 Multi-armed Bandits

Multi-armed bandits (MABs) are a simple yet powerful framework for sequential decision-making under uncertainty. In this project, we have implemented Thompson Sampling, Thompson sampling contextual MAB with linear payoffs, Thompson sampling MABs with fair exposure, and SquareCB contextual MAB with a regression oracle.

## Dependencies
- <img src="https://iconape.com/wp-content/files/zt/11663/png/python.png" width="15" height="15"/> Language: Python 3.8.8

## Directory
- `ProjectSpec.pdf`: description for the assignment
- `code`: contains notebook and data for the assignment